{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"emotions_RACNN2.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"12y5rycv1POaZXIzxt7K_aTtGCXVHButx","authorship_tag":"ABX9TyMMwT/JsjoihJ05yXnNEhok"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"1aa9ef25fac44bc8a433b2c7706b181f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_206f780e71af47689c58c08d0b3be5e4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8b0c1cea25cf4725a2364172bc6f4988","IPY_MODEL_bcffb1b720684bbd93874a994752d5c4","IPY_MODEL_c42bc32faeda4e9681c5fd619857ab31"]}},"206f780e71af47689c58c08d0b3be5e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8b0c1cea25cf4725a2364172bc6f4988":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_435bf4a4a659439088cb5c210aa1119d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"training...: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_89be75b8b61f4ac286d1d254d4de9fe6"}},"bcffb1b720684bbd93874a994752d5c4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_356d564d300c46a7a1b097b5a0c195f7","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":690,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":690,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_426f3caf66904970898b1deddb8e6d96"}},"c42bc32faeda4e9681c5fd619857ab31":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9fb6b419ec7b4c1db691f12e71a7c068","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 690/690 [00:39&lt;00:00, 18.28it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a87f8bcb0ddf417b91d1f8fdbc63f34d"}},"435bf4a4a659439088cb5c210aa1119d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"89be75b8b61f4ac286d1d254d4de9fe6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"356d564d300c46a7a1b097b5a0c195f7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"426f3caf66904970898b1deddb8e6d96":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9fb6b419ec7b4c1db691f12e71a7c068":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a87f8bcb0ddf417b91d1f8fdbc63f34d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bf3f0e9552a44a47b2054386e98c28c0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_37b2aac46c864aafbc2c5f71c9d92fa6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_31739e9dfc524f469167f1b47933388f","IPY_MODEL_972611c8aacf488e8972926f2d07af4e","IPY_MODEL_ca09f41ffad04bd19fdd8500cdf5a1ae"]}},"37b2aac46c864aafbc2c5f71c9d92fa6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"31739e9dfc524f469167f1b47933388f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_759a413cbb044ed6a581ae1a4ee5109f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"predicting...: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f17d41c372e54a39bb221891ad72edf2"}},"972611c8aacf488e8972926f2d07af4e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d5e3b2c91550420a9ae0c3ee754c9d9b","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":77,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":77,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_41ae871f0fbc4f04ab6a6e043de28f7a"}},"ca09f41ffad04bd19fdd8500cdf5a1ae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4dc1ad84219d4ddaba3ca3e93af5e532","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 77/77 [00:04&lt;00:00, 17.12it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7ef55156821745cf80102e6859244318"}},"759a413cbb044ed6a581ae1a4ee5109f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f17d41c372e54a39bb221891ad72edf2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d5e3b2c91550420a9ae0c3ee754c9d9b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"41ae871f0fbc4f04ab6a6e043de28f7a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4dc1ad84219d4ddaba3ca3e93af5e532":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7ef55156821745cf80102e6859244318":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"bA0MKeOZaZ3X"},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchtext\n","import random\n","import math\n","import time\n","import torch.nn.functional as F\n","\n","from tqdm.notebook import tqdm\n","from torch import optim\n","from torch.utils.data import DataLoader, Dataset\n","import numpy as np\n","np.random.seed(1)\n","torch.manual_seed(1)\n","random.seed(1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q8i6x4kaxXah"},"source":["import os\n","os.chdir(\"/content/drive/MyDrive/MADE/Project/deap\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"quQeqXQ4b7K-"},"source":["def get_padding(in_size, kernel_size, stride):\n","    if (in_size % stride == 0):\n","        padding = max(kernel_size - stride, 0)\n","    else:\n","        padding = max(kernel_size - (in_size % stride), 0)\n","    return (padding)    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eUqO7ou9aAH-"},"source":["def get_temporal_feature_extractor(input_size):\n","  pad = get_padding(input_size, 5,  2)\n","  conv1 = nn.Conv3d(1, 32, kernel_size = (1, 1, 5), stride=(1, 1, 2), padding=(0, 0, pad))\n","  relu1 = nn.ReLU()\n","  pad = get_padding(input_size, 3,  2)\n","  conv2 = nn.Conv3d(32, 32, kernel_size = (1, 1, 3), stride=(1, 1, 2), padding=(0, 0, pad))\n","  relu2 = nn.ReLU()\n","  conv3 = nn.Conv3d(32, 32, kernel_size = (1, 1, 3), stride=(1, 1, 2), padding=(0, 0, pad))\n","  relu3 = nn.ReLU()\n","  conv4 = nn.Conv3d(32, 32, kernel_size = (1, 1, 16), stride=(1, 1, 16), padding=0)\n","  relu4 = nn.ReLU()\n","  #print(\"11\")\n","  result = torch.nn.Sequential(conv1, relu1, conv2, relu2, conv3, relu3, conv4, relu4)\n","  #print(\"22\")\n","  #print(result)\n","  return(result)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zIxL2BZYcic1"},"source":["def get_regional_feature_extractor():\n","  conv1 = nn.Conv2d(32, 32, kernel_size = (3, 3), stride=1 , padding='same')\n","  relu1 = nn.ReLU()\n","  conv2 = nn.Conv2d(32, 32, kernel_size = (3, 3), stride=1 , padding='same')\n","  relu2 = nn.ReLU()\n","  return(torch.nn.Sequential(conv1, relu1, conv2, relu2))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pmu1NPeMeWsK"},"source":["class Asymmetric_feature_extractor(torch.nn.Module): \n","   def __init__(self):\n","     super().__init__()\n","     self.conv = nn.Conv2d(32, 64, kernel_size = 1, stride=1 , padding='same')\n","     self.relu = nn.ReLU()\n","   def forward(self, input):\n","     #input(bs, h, w, nf)\n","     half_mat = torch.split(input, (4, 1, 4), dim = 2)\n","     #print(half_mat.shape)\n","     input_new =  half_mat[0] -  half_mat[2]\n","     #print(input.shape)\n","     output = self.conv(input_new)\n","     output = self.relu(output)\n","     #print(output.shape)\n","     return output\n","\n","def get_asymmetric_feature_extractor():\n","    return (Asymmetric_feature_extractor())\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sid_9kKcacdc"},"source":["class EmotionNet(torch.nn.Module): \n","   def __init__(self, hcanals, wcanals, nfeatures, ntimes_in_sample):\n","      super().__init__()\n","      #print(\"1\")\n","      self.tfe = get_temporal_feature_extractor(ntimes_in_sample) #(bs, 1, h = 9, w = 9, s = 128) -> (bs, h = 9, w = 9, s = 1)\n","      #print(\"2\")\n","      self.rfe = get_regional_feature_extractor() #(h = 9, w = 9, s = 32) -> (h = 9, w = 9, s = 32)\n","      #print(\"3\")\n","      self.afe = get_asymmetric_feature_extractor()\n","      #print(\"4\")\n","      self.flat1 = nn.Flatten(1, 3)\n","      self.flat2 = nn.Flatten(1, 3)\n","      self.input_linear_size = int(hcanals * (wcanals//2)* nfeatures * 2 + hcanals * (wcanals)* nfeatures)\n","      #print(self.input_linear_size)\n","      #print(\"5\")\n","      self.fc1 = nn.Linear(self.input_linear_size, 20)\n","      self.relu1 = nn.ReLU()\n","      self.drop = nn.Dropout(0.3)\n","      self.fc2 = nn.Linear(20, 2)\n","   def forward(self, input):\n","      input = input.unsqueeze(1)\n","      #print(f\"input_shape = {input.shape}\")\n","      \n","      #input (bs, in_canals = 1,  h=9, w=9, s=128)\n","      output_tfe = self.tfe(input)\n","      #print(f\"output_tfe.shape = {output_tfe.shape}\")\n","      #output_tfe (bs, in_canals = 32,  h=9, w=9, s=1)\n","      output_tfe = output_tfe.squeeze(4)\n","      #print(f\"output_tfe.shape = {output_tfe.shape}\")\n","      \n","      #output_rfe (bs, canals = 32,  h=9, w=9)\n","      output_rfe = self.rfe(output_tfe)\n","      #print(f\"output_rfe.shape = {output_rfe.shape}\")\n","\n","      output_afe = self.afe(output_tfe)\n","      #print(f\"output_afe.shape = {output_afe.shape}\")\n","      #output_rfe (bs, canals = 64,  h=4, w=9)\n","      output_rfe_flatten = self.flat1(output_rfe)\n","      #print(f\"output_rfe_flatten.shape = {output_rfe_flatten.shape}\")\n","      output_afe_flatten = self.flat2(output_afe)\n","      #print(f\"output_afe_flatten.shape = {output_afe_flatten.shape}\")\n","      output1 = self.drop(self.fc1(torch.cat((output_rfe_flatten, output_afe_flatten), dim = 1)))\n","      #print(f\"output1.shape = {output1.shape}\")\n","      output1_relu = self.relu1(output1)\n","      #print(f\"output1_relu.shape = {output1_relu.shape}\")\n","      output2 = self.fc2(output1_relu)\n","      #print(f\"output2.shape = {output2.shape}\")\n","      return output2\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TM4dD2hIeK4U"},"source":["LEN_RECORD_IN_SECONDS = 60\n","NVIDEOS = 40\n","HCANALS = 9\n","WCANALS = 9\n","NTIMES_IN_SAMPLE = 128\n","NTIMES_IN_SEC = 128\n","NCANALS = 32\n","NFEATURES = 32\n","electrode_matrix = {}\n","electrode_matrix['FP1'] = [0, 3]\n","electrode_matrix['FP2'] = [0, 5]\n","electrode_matrix['AF3'] = [1, 3]\n","electrode_matrix['AF4'] = [1, 5]\n","electrode_matrix['F7']  = [2, 0]\n","electrode_matrix['F3']  = [2, 2]\n","electrode_matrix['FZ']  = [2, 4]\n","electrode_matrix['F4']  = [2, 6]\n","electrode_matrix['F8']  = [2, 8]\n","electrode_matrix['FC5']  = [3, 1]\n","electrode_matrix['FC1']  = [3, 3]\n","electrode_matrix['FC2']  = [3, 5]\n","electrode_matrix['FC6']  = [3, 7]\n","electrode_matrix['T7']  = [4, 0]\n","electrode_matrix['C3']  = [4, 2]\n","electrode_matrix['CZ']  = [4, 4]\n","electrode_matrix['C4']  = [4, 6]\n","electrode_matrix['T8']  = [4, 8]\n","electrode_matrix['CP5']  = [5, 1]\n","electrode_matrix['CP1']  = [5, 3]\n","electrode_matrix['CP2']  = [5, 5]\n","electrode_matrix['CP6']  = [5, 7]\n","electrode_matrix['P7']  = [6, 0]\n","electrode_matrix['P3']  = [6, 2]\n","electrode_matrix['PZ']  = [6, 4]\n","electrode_matrix['P4']  = [6, 6]\n","electrode_matrix['P8']  = [6, 8]\n","electrode_matrix['PO3'] = [7, 3]\n","electrode_matrix['PO4'] = [7, 5]\n","electrode_matrix['O1'] = [8, 3]\n","electrode_matrix['OZ'] = [8, 4]\n","electrode_matrix['O2'] = [8, 5]\n","\n","list_electrodes = ['FP1', 'AF3', 'F3', 'F7', 'FC5', 'FC1', 'C3',\t'T7',\t'CP5',\t'CP1',\t'P3',\t'P7',\t'PO3',\t'O1',\t'OZ',\t'PZ',\t'FP2',\t'AF4', 'FZ', 'F4', 'F8', 'FC6',\t'FC2',\t'CZ', 'C4', 'T8', 'CP6',\t'CP2',\t'P4', \t'P8',\t'PO4',\t'O2']\n","data_dir = './data_preprocessed_python'\n","TRAIN_SIZE = 0.9\n","THRESHOLD = 5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Oaehvlu03phL"},"source":["import glob\n","import pickle\n","from collections import Counter\n","\n","class EmotionDataset(Dataset):\n","    def __init__ (self, data_dir, type):\n","       self.data = []\n","       self.labels = []\n","       self.cnt = [Counter(), Counter(), Counter(),Counter()]\n","       #data_dir = './data_preprocessed_python'\n","       files = glob.glob(os.path.join(data_dir, \"*.dat\"))\n","       self.type = type\n","       #split = int(LEN_RECORD_IN_SECONDS)# *  TRAIN_SIZE)\n","       \n","       self.len_files = []\n","       for file_data in files:\n","            print(file_data)\n","            raw_data = pickle.load(open(file_data, 'rb'), encoding='latin1')\n","            print(raw_data['data'].shape)\n","            if type == 'train':\n","                self.data.append(raw_data['data'][0 : int(NVIDEOS * TRAIN_SIZE), :, 3 * NTIMES_IN_SEC :LEN_RECORD_IN_SECONDS * NTIMES_IN_SEC + 3 * NTIMES_IN_SEC])\n","                self.len_files.append(int(NVIDEOS * TRAIN_SIZE) *  LEN_RECORD_IN_SECONDS - 1)\n","                self.len_record = LEN_RECORD_IN_SECONDS\n","            else:\n","                self.data.append(raw_data['data'][int(NVIDEOS * TRAIN_SIZE) :, :, 3 * NTIMES_IN_SEC :LEN_RECORD_IN_SECONDS * NTIMES_IN_SEC + 3 * NTIMES_IN_SEC])\n","                self.len_files.append((NVIDEOS  - int(NVIDEOS *TRAIN_SIZE)) * (LEN_RECORD_IN_SECONDS) - 1)\n","                self.len_record = LEN_RECORD_IN_SECONDS\n","            labels = raw_data['labels']\n","            labels = (labels >= THRESHOLD)\n","            for i in range(4):\n","              self.cnt[i].update(list(labels[:, i]))\n","            self.labels.append(labels)\n","            \n","       self.len_cumsum = np.cumsum(self.len_files)     \n","       print(self.data[0].shape)\n","       print(self.labels[0].shape)\n","\n","\n","\n","    def __len__(self):\n","        result =  sum(self.len_files) - 10\n","        return result\n","\n","    def get_index_record(self, item):\n","      for i_file in range(len(self.len_cumsum)):\n","         #print(item, self.len_cumsum[i_file])\n","         if (item > self.len_cumsum[i_file]):\n","            continue\n","         else:\n","            break\n","      if i_file == 0:\n","         index_in_file = item\n","      else:\n","         index_in_file = item  - self.len_cumsum[i_file - 1]\n","      nvideo = index_in_file//(self.len_record)# * LEN_RECORD_IN_SECONDS *  NTIMES_IN_SEC)\n","      nsec = (index_in_file - nvideo * self.len_record) # *   NTIMES_IN_SEC)\n","\n","      return i_file, index_in_file, nvideo, nsec\n","\n","    def __getitem__(self, item):\n","      sample = {}\n","      #print(item)\n","      i_file, index_in_file, nvideo, nsec = self.get_index_record(item)\n","      #print(i_file, index_in_file, nvideo, nsec )\n","      sample['data'] = torch.zeros((HCANALS, WCANALS, NTIMES_IN_SAMPLE))\n","      for i_canal in range(NCANALS):\n","        sample_from_one_canal = torch.FloatTensor(self.data[i_file][nvideo, i_canal, nsec * 128 : nsec * 128 + 128])\n","        #print(sample_from_one_canal.shape)\n","        sample['data'][electrode_matrix[list_electrodes[i_canal]][0],  electrode_matrix[list_electrodes[i_canal]][1]] = sample_from_one_canal\n","      if self.type == 'train' :\n","          sample['labels']  = torch.LongTensor(self.labels[i_file][nvideo])\n","          #print(nvideo)\n","      else:\n","          sample['labels']  = torch.LongTensor(self.labels[i_file][int(NVIDEOS * TRAIN_SIZE) + nvideo])\n","          #print(int(NVIDEOS * TRAIN_SIZE) + nvideo)    \n","      #print(sample)\n","      return sample\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"53e0zIUWljhm"},"source":["def get_model():\n","  model = EmotionNet(HCANALS, WCANALS, NFEATURES, NTIMES_IN_SAMPLE).to(device)\n","  return model\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pBgj1BjIhlnh"},"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model = get_model()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bcPqGPSXx4jj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633707214958,"user_tz":-180,"elapsed":42,"user":{"displayName":"Екатерина Савкина","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00035955096309593783"}},"outputId":"8ec08dcd-3af3-4eb9-ed33-cadc64761309"},"source":["# def init_weights(m):\n","#     for name, param in m.named_parameters():\n","#         if 'weight' in name:\n","#             nn.init.normal_(param.data, mean=0, std=0.01)\n","#         else:\n","#             nn.init.constant_(param.data, 0)\n","            \n","# model.apply(init_weights)\n","\n","def initialize_weights(m):\n","    if hasattr(m, 'weight') and m.weight.dim() > 1:\n","        nn.init.xavier_uniform_(m.weight.data)\n","\n","model.apply(initialize_weights)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["EmotionNet(\n","  (tfe): Sequential(\n","    (0): Conv3d(1, 32, kernel_size=(1, 1, 5), stride=(1, 1, 2), padding=(0, 0, 3))\n","    (1): ReLU()\n","    (2): Conv3d(32, 32, kernel_size=(1, 1, 3), stride=(1, 1, 2), padding=(0, 0, 1))\n","    (3): ReLU()\n","    (4): Conv3d(32, 32, kernel_size=(1, 1, 3), stride=(1, 1, 2), padding=(0, 0, 1))\n","    (5): ReLU()\n","    (6): Conv3d(32, 32, kernel_size=(1, 1, 16), stride=(1, 1, 16))\n","    (7): ReLU()\n","  )\n","  (rfe): Sequential(\n","    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n","    (1): ReLU()\n","    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n","    (3): ReLU()\n","  )\n","  (afe): Asymmetric_feature_extractor(\n","    (conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n","    (relu): ReLU()\n","  )\n","  (flat1): Flatten(start_dim=1, end_dim=3)\n","  (flat2): Flatten(start_dim=1, end_dim=3)\n","  (fc1): Linear(in_features=4896, out_features=20, bias=True)\n","  (relu1): ReLU()\n","  (drop): Dropout(p=0.3, inplace=False)\n","  (fc2): Linear(in_features=20, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"pl95YfoKskTC"},"source":["files = glob.glob(os.path.join(data_dir, \"*.dat\"))\n","files.sort()\n","files = np.asarray(files)\n","nfiles = len(files)\n","koeff1 = 0.99\n","# koeff2 = 0.05\n","ind_train = random.sample(range(nfiles), int(nfiles * koeff1))\n","ind_val = list(set(range(nfiles)) - set(ind_train))\n","#ind_val = random.sample(ind, int(len(ind) * koeff2))\n","# ind_test = list(set(ind) - set(ind_val))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"60uHw5tpczfW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633707214960,"user_tz":-180,"elapsed":31,"user":{"displayName":"Екатерина Савкина","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00035955096309593783"}},"outputId":"f9f9f2fe-bb66-4838-95d5-5090d75837a5"},"source":["print(ind_val)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[26]\n"]}]},{"cell_type":"code","metadata":{"id":"ty8V6MvCzJdT"},"source":["class Args:\n","  def __init__(self): #(data_path, epoch, batch_siz, image_size, learning_rate, weight_deca, learning_rate, learning_rate_gamma, weight_bce, load, output_dir)\n","    self.data_path = \"/content/drive/MyDrive/MADE/semester2/CV/contest02/data/\"\n","    self.epochs = 2\n","    self.batch_size = 100\n","    self.lr= 3e-4\n","    self.weight_decay= 1e-6\n","    self.learning_rate=None\n","    self.learning_rate_gamma=None\n","    self.weight_bce=1\n","    self.load=None\n","    self.output_dir=\"runs/segmentation_baseline\"\n","    self.data_dir =\"./data_preprocessed_python/\"# \"/content/drive/MyDrive/MADE/Project/train/physionet.org/\"\n","args = Args()    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L2lPXmuCYbUI"},"source":["train_dataset = EmotionDataset(args.data_dir, 'train')\n","train_dataloader = DataLoader(train_dataset, batch_size=args.batch_size, num_workers=1,\n","                              pin_memory=True, shuffle=True, drop_last=True)\n","\n","\n","val_dataset = EmotionDataset(args.data_dir, 'val')\n","val_dataloader = DataLoader(val_dataset, batch_size=args.batch_size, num_workers=1,\n","                              pin_memory=True, shuffle=False, drop_last=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mOT0qjQSLPUy"},"source":["# train_dataset = EmotionDataset(files[ind_train])\n","# train_dataloader = DataLoader(train_dataset, batch_size=args.batch_size, num_workers=1,\n","#                               pin_memory=True, shuffle=True, drop_last=True)\n","\n","\n","# val_dataset = EmotionDataset(files[ind_val])\n","# val_dataloader = DataLoader(val_dataset, batch_size=args.batch_size, num_workers=1,\n","#                               pin_memory=True, shuffle=False, drop_last=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7lrXjgrpcgiM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633707227092,"user_tz":-180,"elapsed":34,"user":{"displayName":"Екатерина Савкина","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00035955096309593783"}},"outputId":"8aac8825-a185-4f28-bfe7-9a702858df09"},"source":["criterion = nn.CrossEntropyLoss(reduce = 'mean')#torch.nn.MSELoss()\n","#optimizer = optim.SGD(model.parameters(), lr=3e-5, momentum = 0.9)#, weight_decay=args.weight_decay)\n","optimizer = optim.Adam(model.parameters(), lr=3e-4)#, momentum = 0.9)#, weight_decay=args.weight_decay)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n","  warnings.warn(warning.format(ret))\n"]}]},{"cell_type":"code","metadata":{"id":"5In2kzycPvri"},"source":["# print(train_dataset.cnt)\n","# print(val_dataset.cnt)\n","# print(files[ind_train])\n","# print(files[ind_val])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DRGvG4QaaYl6"},"source":["def train(model, loader, criterion, optimizer, device, batch = None):\n","    model.train()\n","    train_loss = []\n","    inputs = []\n","   \n","    #lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)#, mode='min', factor=0.1, patience=10, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08, verbose=False)\n","    for batch in tqdm(loader, total=len(loader), desc=\"training...\", position=0 , leave = True):\n","\n","            optimizer.zero_grad()\n","            src  = batch['data'].to(device)\n","            #print(src.shape)\n","            trg = batch['labels'][:, 0]\n","\n","            #print(batch)\n","            #print(trg.shape)\n","            levels_pred = model(src)  # B x (2 * NUM_PTS)\n","            #print(levels_pred.shape)\n","            levels_pred = levels_pred.cpu()\n","\n","            #usual cross entropy\n","            #output = levels_pred[:, 1:].reshape(-1, levels_pred.shape[-1])\n","            #trg1 = trg[:, 1:].reshape(-1)\n","            loss = criterion(levels_pred, trg) \n","\n","            ##trg1 = trg[:, 1:].reshape(-1)\n","            ##output = levels_pred[:, 1:].reshape(-1, levels_pred.shape[-1])\n","            #print(trg1.shape)\n","            #print(output.shape)\n","            ##loss = 0\n","            #print(trg1.shape)\n","            #print(trg1)\n","            #print(\"*********************\")\n","            ##for i in range(OUTPUT_DIM):\n","              ##  output_class = output[trg1 == i]\n","              ##  trg_class = trg1[trg1 == i]\n","                #print(trg_class.shape)\n","               ## if (trg_class.shape[0] != 0):\n","                 ##   if (i == 2) or (i == 3):\n","                   ##    loss += 2 * criterion(output_class, trg_class)/trg_class.shape[0]\n","\n","            \n","            #print(\"after\")\n","            train_loss.append(loss.item())\n","            loss.backward()\n","            optimizer.step()\n","            #break\n","    return np.mean(train_loss)#, mid_outputs\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XiYcR4aI_I_v"},"source":["def evaluate(model, loader, criterion, device):\n","    \n","    model.eval()\n","    epoch_loss = 0\n","    history = []\n","  \n","    with torch.no_grad():\n","    \n","        for s, batch in enumerate(tqdm(loader, total=len(loader), desc=\"validating...\", position=0 , leave = True)):\n","            src  = batch['data'].to(device)\n","            #print(src.shape)\n","            trg = batch['labels'][:, 0]\n","\n","\n","\n","            levels_pred = model(src)  # B x (2 * NUM_PTS)\n","            #print(levels_pred.shape)\n","            levels_pred = levels_pred.cpu()\n","\n","            #usual cross entropy\n","            #output = levels_pred[:, 1:].reshape(-1, levels_pred.shape[-1])\n","            #trg1 = trg[:, 1:].reshape(-1)\n","            loss = criterion(levels_pred, trg) \n","\n","            #trg1 = trg[:, 1:].reshape(-1)\n","            #output = levels_pred[:, 1:].reshape(-1, levels_pred.shape[-1])\n","            #print(trg1.shape)\n","            #print(output.shape)\n","            #loss = 0\n","            #print(trg1.shape)\n","            #print(trg1)\n","            ##for i in range(OUTPUT_DIM):\n","              ##  output_class = output[trg1 == i]\n","              ##  trg_class = trg1[trg1 == i]\n","                #print(trg_class.shape)\n","               # if (trg_class.shape[0] != 0):\n","                    #print(cnt[i], i)\n","                #    loss += criterion(output_class, trg_class)/trg_class.shape[0]\n","\n","            epoch_loss += loss.item() \n","        \n","    return epoch_loss / s"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"osXxKvs4nAAQ"},"source":["from sklearn.metrics import accuracy_score, confusion_matrix,classification_report\n","\n","def calculate_predictions(model, loader):\n","    model.eval()\n","    epoch_loss = 0\n","    history = []\n","    real = []\n","    pred = []\n","    with torch.no_grad():\n","\n","        for i, batch in enumerate(tqdm(loader, total=len(loader), desc=\"predicting...\", position=0 , leave = True)):\n","            src  = batch['data'].to(device)\n","            #print(src.shape)\n","            trg = batch['labels'][:, 0]\n","           \n","\n","            levels_pred = model(src)  # B x (2 * NUM_PTS)\n","            levels_pred = levels_pred.cpu()\n","            #print(levels_pred.shape)\n","            trg_pred = levels_pred.argmax(1)\n","            \n","            real.extend(trg)\n","            pred.extend(trg_pred) \n","\n","            \n","        print(accuracy_score(real, pred)) \n","        print(confusion_matrix(real, pred))  \n","        print(classification_report(real, pred))   \n","        #plt.hist(real)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LcnMLBs0fWUq","colab":{"base_uri":"https://localhost:8080/","height":682,"referenced_widgets":["1aa9ef25fac44bc8a433b2c7706b181f","206f780e71af47689c58c08d0b3be5e4","8b0c1cea25cf4725a2364172bc6f4988","bcffb1b720684bbd93874a994752d5c4","c42bc32faeda4e9681c5fd619857ab31","435bf4a4a659439088cb5c210aa1119d","89be75b8b61f4ac286d1d254d4de9fe6","356d564d300c46a7a1b097b5a0c195f7","426f3caf66904970898b1deddb8e6d96","9fb6b419ec7b4c1db691f12e71a7c068","a87f8bcb0ddf417b91d1f8fdbc63f34d","3b1ce71ca6f34f7b923d63cc5c5cb1f6","288fc1b964ac469cb7f8a9ccda3f6832","c835ad397b844207b556b75855d7a723","e4f52697b6ac4d3f9c0b74bf0865cd2b","9c7bcf45274648529278f1460dfa1df4","60362f8ea2a24474951dd4e38e406bea"]},"executionInfo":{"status":"error","timestamp":1633707374811,"user_tz":-180,"elapsed":147333,"user":{"displayName":"Екатерина Савкина","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00035955096309593783"}},"outputId":"c07e3065-c3d5-4424-b4a2-e8936c38bbd7"},"source":["args.epochs = 20000\n","#criterion =  fnn.mse_loss\n","train_loss_min = 10000\n","val_loss_min = 10000\n","#batch = next(iter(train_dataloader))\n","for epoch in range(args.epochs):\n","    #logger.info(f\"Starting epoch {epoch + 1}/{args.epochs}.\")\n","    \n","    train_loss = train(model, train_dataloader, criterion, optimizer ,device)\n","    #if epoch % 500 == 0:\n","    print(train_loss)\n","\n","    if (train_loss < train_loss_min):\n","        train_loss_min      = train_loss\n","        torch.save({\n","                         'model_state_dict': model.state_dict(),\n","                         'optimizer_state_dict': optimizer.state_dict(),\n","                       },\n","                       os.path.join(\"/content/drive/MyDrive/MADE/Project/RACNN_models/\", \"train.tgz\")\n","            )  \n","\n","    val_loss = evaluate(model, val_dataloader, criterion, device)\n","    # #break\n","    print(val_loss)\n","\n","    # #calculate_predictions(model, val_dataloader)\n","    # if (val_loss < val_loss_min):\n","    #     val_loss_min      = val_loss\n","    #     torch.save({'model_state_dict': model.state_dict(),    'optimizer_state_dict': optimizer.state_dict(),}, os.path.join(\"/content/drive/MyDrive/MADE/Project/RACNN_models/\", f\"val.tgz\"))"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1aa9ef25fac44bc8a433b2c7706b181f","version_minor":0,"version_major":2},"text/plain":["training...:   0%|          | 0/690 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["0.6778491351051606\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3b1ce71ca6f34f7b923d63cc5c5cb1f6","version_minor":0,"version_major":2},"text/plain":["validating...:   0%|          | 0/77 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["0.8143276274204254\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"288fc1b964ac469cb7f8a9ccda3f6832","version_minor":0,"version_major":2},"text/plain":["training...:   0%|          | 0/690 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["0.654989844215089\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c835ad397b844207b556b75855d7a723","version_minor":0,"version_major":2},"text/plain":["validating...:   0%|          | 0/77 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["0.8421576768159866\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e4f52697b6ac4d3f9c0b74bf0865cd2b","version_minor":0,"version_major":2},"text/plain":["training...:   0%|          | 0/690 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["0.6375797357248223\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9c7bcf45274648529278f1460dfa1df4","version_minor":0,"version_major":2},"text/plain":["validating...:   0%|          | 0/77 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["0.8776344496168589\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"60362f8ea2a24474951dd4e38e406bea","version_minor":0,"version_major":2},"text/plain":["training...:   0%|          | 0/690 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-245c9cfd36e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#logger.info(f\"Starting epoch {epoch + 1}/{args.epochs}.\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;31m#if epoch % 500 == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-20-1ea3c37b6b1d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loader, criterion, optimizer, device, batch)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)#, mode='min', factor=0.1, patience=10, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08, verbose=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"training...\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1143\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"kjC_9P-qjodh","colab":{"base_uri":"https://localhost:8080/","height":243,"referenced_widgets":["bf3f0e9552a44a47b2054386e98c28c0","37b2aac46c864aafbc2c5f71c9d92fa6","31739e9dfc524f469167f1b47933388f","972611c8aacf488e8972926f2d07af4e","ca09f41ffad04bd19fdd8500cdf5a1ae","759a413cbb044ed6a581ae1a4ee5109f","f17d41c372e54a39bb221891ad72edf2","d5e3b2c91550420a9ae0c3ee754c9d9b","41ae871f0fbc4f04ab6a6e043de28f7a","4dc1ad84219d4ddaba3ca3e93af5e532","7ef55156821745cf80102e6859244318"]},"executionInfo":{"status":"ok","timestamp":1633707392329,"user_tz":-180,"elapsed":3235,"user":{"displayName":"Екатерина Савкина","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00035955096309593783"}},"outputId":"a7c83ab0-8228-48ea-8a55-93e6258e5f03"},"source":["calculate_predictions(model, val_dataloader)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bf3f0e9552a44a47b2054386e98c28c0","version_minor":0,"version_major":2},"text/plain":["predicting...:   0%|          | 0/77 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["0.5145326001571092\n","[[2644 3029]\n"," [ 679 1286]]\n","              precision    recall  f1-score   support\n","\n","           0       0.80      0.47      0.59      5673\n","           1       0.30      0.65      0.41      1965\n","\n","    accuracy                           0.51      7638\n","   macro avg       0.55      0.56      0.50      7638\n","weighted avg       0.67      0.51      0.54      7638\n","\n"]}]}]}