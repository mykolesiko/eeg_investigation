{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MADE_baseline_report_noneutral_article.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1VPpXcJa2tya_sOTbkw9diBPIII1naE5v",
      "authorship_tag": "ABX9TyMZ2SexTqocpHMhpkfFiFk4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mykolesiko/eeg_investigation/blob/diplom/MADE_baseline_report_noneutral_article.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDkd48c7n40R"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/MADE/Project/deap\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJeF0XZWNYFe"
      },
      "source": [
        "import pickle\n",
        "x = pickle.load(open('./data_preprocessed_python/s01.dat', 'rb'), encoding='latin1')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hfdlSK5RKwl"
      },
      "source": [
        "data = x['data']\n",
        "labels = x['labels']"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJbPGmAkj_BK"
      },
      "source": [
        "The logarithms of the spectral power from\n",
        "theta (4-8 Hz), slow alpha (8-10 Hz), alpha (8-12 Hz), beta\n",
        "(12-30Hz) and gamma (30+ Hz) bands were extracted\n",
        "from all 32 electrodes as features. In addition to power\n",
        "spectral features the difference between the spectral\n",
        "power of all the symmetrical pairs of electrodes on\n",
        "the right and left hemisphere was extracted to measure\n",
        "the possible asymmetry in the brain activities due to\n",
        "emotional stimuli. The total number of EEG features of\n",
        "a trial for 32 electrodes is 216."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXdnb4Nyju7c"
      },
      "source": [
        "import scipy\n",
        "from  scipy import signal\n",
        "freq, power = signal.welch(data[0][0], fs=128.0, window='hanning', nperseg=256, noverlap=None, nfft=None, detrend='constant', return_onesided=True, scaling='density', axis=-1)\n",
        "freq_ranges = [range(4,9), range(8,11), range(8,13), range(12, 31), range(30,48)]\n",
        "pairs_canals = [[1, 17], [2, 18], [3, 20], [4, 21], [5, 22], [6, 23], [7, 25], [8, 26], [9, 27], [10, 28], [11, 29], [12, 30], [13, 31], [14, 32]]\n",
        "#FC5-CP5, FC1-CP1, FC2-CP2, FC6-CP6, F7-P7, F3-P3, Fz-Pz,F4-P4, F8-P8, Fp1-O1, Fp2-O2\n",
        "pairs_canals_1 = [[6, 21], [5, 9], [26, 30], [21, 25], [3, 11], [4, 12], [31, 32], [27, 19], [28, 20], [1, 15], [30, 17] ]\n",
        "import numpy as np\n",
        "import scipy\n",
        "from scipy import stats\n",
        "freq_resolution = max(freq)/(len(freq) - 1)\n",
        "max_freq = 128\n",
        "NVIDEOS = 40\n",
        "NCANALS = 32"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdXzzli5lL5M"
      },
      "source": [
        "# import numpy as np\n",
        "# import scipy\n",
        "# from scipy import stats\n",
        "# freq_resolution = max(freq)/(len(freq) - 1)\n",
        "# from scipy.integrate import simps\n",
        "# max_freq = 128\n",
        "# NVIDEOS = 40\n",
        "# NCANALS = 32\n",
        "# def get_features_whole(data, labels, freq_resolution, max_freq):\n",
        "#   data_for_videos = []\n",
        "#   for id in range(NVIDEOS):\n",
        "#     data_for_one_video = []\n",
        "#     powers = np.zeros((NCANALS, 5))\n",
        "#     for i in range(NCANALS):\n",
        "        \n",
        "#         freq, power = scipy.signal.welch(data[id][i], fs=max_freq, window='hanning', nperseg=256, noverlap=None, nfft=None, detrend='constant', return_onesided=True, scaling='density', axis=-1)\n",
        "#         #one_canal = []\n",
        "#         powers_temp  = []\n",
        "#         for k, interval in enumerate(freq_ranges):\n",
        "#             ar = np.asarray(interval)\n",
        "#             ar = range(int(interval[0]/freq_resolution), int((interval[-1] + 1)/freq_resolution))#(ar / freq_resolution).astype(int)\n",
        "#             #print(ar)\n",
        "#             power_range = power[ar]\n",
        "#             mean_power = simps(power[ar], dx = 0.5)#(power_range).sum()/len(power_range)\n",
        "#             data_for_one_video.extend([np.log(mean_power)])\n",
        "#             powers_temp.append(mean_power)\n",
        "#             powers[i, k] = mean_power\n",
        "#         #for s in range(5):\n",
        "#          #  for k in range(s):\n",
        "#           #   data_for_one_video.extend([powers_temp[s]/powers_temp[k]])\n",
        "\n",
        "            \n",
        "#     for pair in pairs_canals:\n",
        "#         canal_1 = pair[0] - 1\n",
        "#         canal_2 = pair[1] - 1\n",
        "#         temp = np.log(powers[canal_1]) -  np.log(powers[canal_2])\n",
        "#         #print(temp)\n",
        "#         data_for_one_video.extend(temp[[0, 2, 3, 4]].tolist())  \n",
        "\n",
        "#         temp = np.log(powers[canal_1])/np.log(powers[canal_2])\n",
        "#         #print(temp)\n",
        "#         data_for_one_video.extend(temp[[0, 2, 3, 4]].tolist())       \n",
        "#         #data_for_one_video.append(one_canal)    \n",
        "#     #for s in range(5 * NCANALS):\n",
        "#     #  data_for_one_video[s] = np.log(data_for_one_video[s])\n",
        "\n",
        "#     temp = np.asarray(data_for_one_video)\n",
        "#     temp[0:160] = stats.zscore(temp[0:160])\n",
        "#     temp[160:] = stats.zscore(temp[160:])\n",
        "#     data_for_videos.append(temp.copy())    \n",
        "#     result = np.asarray(data_for_videos)   \n",
        "#     #result = stats.zscore(result)\n",
        "#     #result[0:160] = stats.zscore(result[0:160])\n",
        "#     #result[160:] = stats.zscore(result[160:])\n",
        "    \n",
        "#   return result#np.asarray(data_for_videos)     \n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rx8Lk2deefRz"
      },
      "source": [
        "import glob\n",
        "data = []\n",
        "labels = []\n",
        "data_dir = './data_preprocessed_python'\n",
        "files = glob.glob(os.path.join(data_dir, \"*.dat\"))\n",
        "\n",
        "for file_data in files:\n",
        "    raw_data = pickle.load(open(file_data, 'rb'), encoding='latin1')\n",
        "    data.append(raw_data['data'])\n",
        "    labels.append(raw_data['labels'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "labels_3 = []\n",
        "for i in range(32):\n",
        "  neg = labels[i] < 3.5\n",
        "  pos = labels[i] >= 5.5\n",
        "  temp = np.zeros_like(labels[i], np.int8)\n",
        "  temp[neg] = 1\n",
        "  temp[pos] = 2\n",
        "  #print(labels[i])\n",
        "  #print(temp)\n",
        "  labels_3.append(temp)\n",
        "  cnt1 = Counter()\n",
        "  cnt1.update(temp[:, 0])\n",
        "  cnt2 = Counter()\n",
        "  cnt2.update(temp[:, 1])\n",
        "  print(cnt1, cnt2)\n",
        "  #break\n",
        "  #print(temp)\n",
        "labels_all_3 = np.vstack(labels_3)  "
      ],
      "metadata": {
        "id": "BV8Ho61fMLii",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4844e4f4-2eaf-4f44-c418-16810e6efb44"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({2: 18, 1: 16, 0: 6}) Counter({2: 24, 1: 11, 0: 5})\n",
            "Counter({2: 22, 0: 10, 1: 8}) Counter({0: 17, 2: 16, 1: 7})\n",
            "Counter({2: 26, 0: 12, 1: 2}) Counter({0: 17, 2: 14, 1: 9})\n",
            "Counter({2: 25, 1: 9, 0: 6}) Counter({2: 22, 1: 10, 0: 8})\n",
            "Counter({0: 20, 2: 15, 1: 5}) Counter({2: 18, 0: 18, 1: 4})\n",
            "Counter({0: 19, 2: 13, 1: 8}) Counter({0: 20, 2: 20})\n",
            "Counter({2: 18, 0: 13, 1: 9}) Counter({2: 17, 0: 14, 1: 9})\n",
            "Counter({2: 19, 0: 12, 1: 9}) Counter({1: 19, 2: 12, 0: 9})\n",
            "Counter({2: 17, 1: 15, 0: 8}) Counter({2: 26, 0: 9, 1: 5})\n",
            "Counter({0: 15, 2: 13, 1: 12}) Counter({2: 32, 0: 5, 1: 3})\n",
            "Counter({2: 20, 1: 16, 0: 4}) Counter({2: 27, 1: 11, 0: 2})\n",
            "Counter({2: 17, 0: 13, 1: 10}) Counter({0: 22, 2: 10, 1: 8})\n",
            "Counter({0: 15, 1: 13, 2: 12}) Counter({2: 17, 0: 13, 1: 10})\n",
            "Counter({2: 21, 0: 15, 1: 4}) Counter({2: 24, 0: 12, 1: 4})\n",
            "Counter({2: 21, 0: 17, 1: 2}) Counter({2: 22, 0: 15, 1: 3})\n",
            "Counter({2: 19, 0: 11, 1: 10}) Counter({2: 25, 0: 8, 1: 7})\n",
            "Counter({2: 17, 0: 16, 1: 7}) Counter({2: 21, 0: 15, 1: 4})\n",
            "Counter({2: 19, 0: 13, 1: 8}) Counter({2: 31, 0: 5, 1: 4})\n",
            "Counter({2: 15, 1: 15, 0: 10}) Counter({2: 22, 0: 10, 1: 8})\n",
            "Counter({2: 19, 0: 18, 1: 3}) Counter({1: 23, 0: 9, 2: 8})\n",
            "Counter({2: 16, 0: 13, 1: 11}) Counter({2: 27, 0: 9, 1: 4})\n",
            "Counter({2: 15, 1: 15, 0: 10}) Counter({2: 26, 1: 8, 0: 6})\n",
            "Counter({2: 24, 1: 12, 0: 4}) Counter({1: 17, 2: 12, 0: 11})\n",
            "Counter({2: 22, 0: 13, 1: 5}) Counter({2: 16, 0: 12, 1: 12})\n",
            "Counter({2: 22, 1: 13, 0: 5}) Counter({1: 19, 2: 18, 0: 3})\n",
            "Counter({2: 20, 1: 12, 0: 8}) Counter({2: 22, 1: 11, 0: 7})\n",
            "Counter({0: 22, 2: 15, 1: 3}) Counter({0: 20, 2: 14, 1: 6})\n",
            "Counter({2: 18, 0: 15, 1: 7}) Counter({2: 16, 1: 13, 0: 11})\n",
            "Counter({2: 18, 0: 17, 1: 5}) Counter({2: 25, 0: 11, 1: 4})\n",
            "Counter({0: 20, 2: 17, 1: 3}) Counter({1: 20, 0: 14, 2: 6})\n",
            "Counter({1: 20, 2: 14, 0: 6}) Counter({1: 18, 0: 11, 2: 11})\n",
            "Counter({2: 20, 0: 11, 1: 9}) Counter({2: 21, 1: 13, 0: 6})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "labels_3 = []\n",
        "for i in range(32):\n",
        "  neg = labels[i] < 4.5\n",
        "  pos = labels[i] >= 4.5\n",
        "  temp = np.zeros_like(labels[i], np.int8)\n",
        "  temp[neg] = 1\n",
        "  temp[pos] = 2\n",
        "  #print(labels[i])\n",
        "  #print(temp)\n",
        "  labels_3.append(temp)\n",
        "  cnt1 = Counter()\n",
        "  cnt1.update(temp[:, 0])\n",
        "  cnt2 = Counter()\n",
        "  cnt2.update(temp[:, 1])\n",
        "  print(cnt1, cnt2)\n",
        "  #break\n",
        "  #print(temp)\n",
        "labels_all_3 = np.vstack(labels_3)  "
      ],
      "metadata": {
        "id": "O_QxvRLW1riM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0YlHbU_WVfZ"
      },
      "source": [
        "import numpy as np\n",
        "import scipy\n",
        "from scipy import stats\n",
        "freq_resolution = max(freq)/(len(freq) - 1)\n",
        "from scipy.integrate import simps\n",
        "max_freq = 128\n",
        "NVIDEOS = 40\n",
        "NCANALS = 32\n",
        "def get_features_whole2(data, labels, freq_resolution, max_freq):\n",
        "  data_for_videos = []\n",
        "  for id in range(NVIDEOS):\n",
        "    data_for_one_video = []\n",
        "    powers = np.zeros((NCANALS, 5))\n",
        "    for i in range(NCANALS):\n",
        "        \n",
        "        freq, power = scipy.signal.welch(data[id][i], fs=max_freq, window='hanning', nperseg=256, noverlap=None, nfft=None, detrend='constant', return_onesided=True, scaling='density', axis=-1)\n",
        "        #one_canal = []\n",
        "        powers_temp  = []\n",
        "        for k, interval in enumerate(freq_ranges):\n",
        "            ar = np.asarray(interval)\n",
        "            ar = range(int(interval[0]/freq_resolution), int((interval[-1] + 1)/freq_resolution))#(ar / freq_resolution).astype(int)\n",
        "            #print(ar)\n",
        "            power_range = power[ar]\n",
        "            mean_power = simps(power[ar], dx = 0.5)#(power_range).sum()/len(power_range)\n",
        "            data_for_one_video.extend([np.log(mean_power)])\n",
        "            powers_temp.append(mean_power)\n",
        "            powers[i, k] = mean_power\n",
        "        #for s in range(5):\n",
        "         #  for k in range(s):\n",
        "          #   data_for_one_video.extend([powers_temp[s]/powers_temp[k]])\n",
        "\n",
        "            \n",
        "    for pair in pairs_canals:\n",
        "        canal_1 = pair[0] - 1\n",
        "        canal_2 = pair[1] - 1\n",
        "        temp = np.log(powers[canal_1]) -  np.log(powers[canal_2])\n",
        "        #print(temp)\n",
        "        data_for_one_video.extend(temp[[0, 2, 3, 4]].tolist())  \n",
        "\n",
        "        temp = np.log(powers[canal_1])/np.log(powers[canal_2])\n",
        "        #print(temp)\n",
        "        data_for_one_video.extend(temp[[0, 2, 3, 4]].tolist())       \n",
        "        #data_for_one_video.append(one_canal)    \n",
        "\n",
        "    for pair in pairs_canals_1:\n",
        "        canal_1 = pair[0] - 1\n",
        "        canal_2 = pair[1] - 1\n",
        "        temp =  np.log(powers[canal_1]) -   np.log(powers[canal_2])\n",
        "        #print(temp)\n",
        "        data_for_one_video.extend(temp[[0, 1, 2, 3, 4]].tolist())  \n",
        "\n",
        "        #temp = powers[canal_1]/powers[canal_2]\n",
        "        #print(temp)\n",
        "        #data_for_one_video.extend(temp[[0, 2, 3, 4]].tolist())           \n",
        "    #for s in range(5 * NCANALS):\n",
        "    #  data_for_one_video[s] = np.log(data_for_one_video[s])\n",
        "\n",
        "    temp = np.asarray(data_for_one_video)\n",
        "    #temp[0:160] = stats.zscore(temp[0:160])\n",
        "    #temp[160:] = stats.zscore(temp[160:])\n",
        "    data_for_videos.append(temp.copy())    \n",
        "    result = np.asarray(data_for_videos)   \n",
        "    #result = stats.zscore(result)\n",
        "    #result[0:160] = stats.zscore(result[0:160])\n",
        "    #result[160:] = stats.zscore(result[160:])\n",
        "    \n",
        "  return result#np.asarray(data_for_videos)     \n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Cq_8IpdyWXWx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_for_videos = []\n",
        "for i in  range(len(data)):\n",
        "    data_for_videos.append(get_features_whole2(data[i], labels[i], freq_resolution, max_freq))"
      ],
      "metadata": {
        "id": "14a7MN4sWVfQ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VbhIZTbH8j04"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed8b8b95-b789-4030-9d39-c3862f00d261",
        "id": "SMuOTe9H8kI_"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold , KFold\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from sklearn.naive_bayes import  GaussianNB\n",
        "from sklearn.model_selection import StratifiedKFold \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from imblearn.over_sampling import RandomOverSampler \n",
        "import pandas as pd\n",
        "from sklearn import svm\n",
        "import lightgbm as lgbm\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "#threshold = 0.5\n",
        "k = 5\n",
        "labels_common = []\n",
        "emotion = ['valence', 'arousal', 'dominance', 'like']\n",
        "\n",
        "for i_em in range(4):\n",
        "        print(i_em)\n",
        "        f1_all = []\n",
        "        acc_all = []\n",
        "        train_indexes = []\n",
        "        test_indexes = []\n",
        "        for j in range(32):\n",
        "                # labels_common.append([np.mean(labels_all_bin[:, i_em][i::NVIDEOS]) > 0.5 for i in range(NVIDEOS)])\n",
        "            train_indexes.append([])    \n",
        "            test_indexes.append([])    \n",
        "            #X = np.arange(40)\n",
        "            y = np.array(labels_3[j][:, i_em])\n",
        "            y = y[y!=0]\n",
        "           # print(y)\n",
        "            X = np.arange(len(y))\n",
        "            \n",
        "            if len(y) != 0 :\n",
        "                skf = StratifiedKFold(n_splits=k, random_state=2021, shuffle=True)\n",
        "                #kf = KFold(n_splits=k, random_state=None, shuffle=True)\n",
        "                for fold, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
        "                #for fold, (train_index, test_index) in enumerate(kf.split(X)):\n",
        "                    train_indexes[-1].append(train_index)\n",
        "                    test_indexes[-1].append(test_index)\n",
        "            else:\n",
        "               for fold in range(k):\n",
        "                  train_indexes[-1].append([])\n",
        "                  test_indexes[-1].append([])      \n",
        "        \n",
        "        f1_data = pd.DataFrame(columns = range(k), index = range(32))\n",
        "        acc_data = pd.DataFrame(columns = range(k), index = range(32))\n",
        "\n",
        "        for fold in range(k):\n",
        "            print(fold)\n",
        "            f1_sub = []\n",
        "            acc_sub = []\n",
        "\n",
        "            data_train = []\n",
        "            data_test = []\n",
        "            labels_train = []\n",
        "            labels_test = []\n",
        "            labels_check = []\n",
        "            for i in range(32):\n",
        "             \n",
        "                  #print( labels_subject_train[i])\n",
        "               ltemp = labels_3[i][:, i_em]\n",
        "\n",
        "                  #print(ltemp)\n",
        "               ltemp1 = ltemp[ltemp != 0]\n",
        "               if len(ltemp1) != 0:   \n",
        "                  data_temp = data_for_videos[i][ltemp != 0 ]\n",
        "                  #print(ltemp1)\n",
        "                  #print(data_temp.shape)\n",
        "                  data_subject_train = data_temp[train_indexes[i][fold]]\n",
        "                  labels_subject_train = ltemp1[train_indexes[i][fold]]\n",
        "\n",
        "\n",
        "                  #if len(labels_subject_train[labels_subject_train == 1]) != 0 and  len(labels_subject_train[labels_subject_train == 2]) != 0:\n",
        "                  #    ros = RandomOverSampler(random_state=42)\n",
        "                  #    data_subject_train, labels_subject_train = ros.fit_resample(data_subject_train, labels_subject_train)\n",
        "\n",
        "                  data_train.append(data_subject_train)\n",
        "                  labels_train.extend(labels_subject_train)\n",
        "\n",
        "                  data_subject_test = data_temp[test_indexes[i][fold]]\n",
        "                  labels_subject_test = ltemp1[test_indexes[i][fold]]\n",
        "                  #if len(labels_subject_test[labels_subject_test == 1]) != 0 and  len(labels_subject_test[labels_subject_test == 2]) != 0:\n",
        "                  #    ros = RandomOverSampler(random_state=42)\n",
        "                  #    data_subject_test, labels_subject_test = ros.fit_resample(data_subject_test, labels_subject_test)\n",
        "\n",
        "                  data_test.append(data_subject_test)\n",
        "                  labels_test.extend(labels_subject_test)\n",
        "                  labels_check.append(labels_subject_test)\n",
        "\n",
        "            data_train_all = np.vstack(data_train)\n",
        "            data_test_all = np.vstack(data_test)   \n",
        "            data_all = np.vstack((data_train_all, data_test_all))\n",
        "            labels_all = np.hstack((labels_train, labels_test))\n",
        "            #print(len(labels_train))\n",
        "            #print(data_train_all.shape)\n",
        "\n",
        "            model = lgbm.sklearn.LGBMClassifier(n_estimators = 100, class_weight = 'balanced')#!!!!!!!\n",
        "            model.fit(data_train_all, labels_train)\n",
        "            cnt_train = Counter()\n",
        "            cnt_train.update(labels_train)\n",
        "            #print(labels_train)\n",
        "            print(cnt_train)\n",
        "            cnt_test = Counter()\n",
        "            cnt_test.update(labels_test)\n",
        "            #print(labels_train)\n",
        "            print(cnt_test)\n",
        "\n",
        "            labels_predicted = model.predict(data_test_all)\n",
        "            f1_all.append(f1_score(labels_predicted, labels_test, average = 'macro'))\n",
        "            acc_all.append(accuracy_score(labels_predicted, labels_test)) \n",
        "            f1_sub = []\n",
        "            acc_sub = []\n",
        "            for i in range(32):\n",
        "                 if len(labels_check[i]) != 0:\n",
        "                     labels_predicted_sub = model.predict(data_test[i])\n",
        "                     #print(labels_predicted_sub)\n",
        "                     f1_data.loc[i, fold] = (f1_score(labels_predicted_sub, labels_check[i], average = 'macro'))\n",
        "                     acc_data.loc[i, fold] =  (accuracy_score(labels_predicted_sub, labels_check[i]))  \n",
        "                 else:\n",
        "                     print(\"!!!!!!\")\n",
        "                     f1_data.loc[i, fold] = 0.5#(f1_score(labels_predicted_sub, labels_check[i], average = 'macro'))\n",
        "                     acc_data.loc[i, fold] = 0.5# (accuracy_score(labels_predicted_sub, labels_check[i]))  \n",
        "\n",
        "\n",
        "                  #print(confusion_matrix(labels_predicted_sub, labels_subject[i]))\n",
        "            #break     \n",
        "        \n",
        "        print(np.mean(f1_data.values.mean(axis = 1)))\n",
        "        print(np.mean(acc_data.values.mean(axis = 1)))\n",
        "\n",
        "        print(\"*************************\")\n",
        "        print(f1_all)\n",
        "        print(acc_all)\n",
        "        print(np.mean(f1_all))    \n",
        "        print(np.mean(acc_all))  \n",
        "        print  \n",
        "                     \n",
        "       "
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({2: 459, 1: 237})\n",
            "Counter({2: 128, 1: 59})\n",
            "1\n",
            "Counter({2: 463, 1: 236})\n",
            "Counter({2: 124, 1: 60})\n",
            "2\n",
            "Counter({2: 470, 1: 237})\n",
            "Counter({2: 117, 1: 59})\n",
            "3\n",
            "Counter({2: 475, 1: 237})\n",
            "Counter({2: 112, 1: 59})\n",
            "4\n",
            "Counter({2: 481, 1: 237})\n",
            "Counter({2: 106, 1: 59})\n",
            "0.663711444805195\n",
            "0.7547544642857142\n",
            "*************************\n",
            "[0.747638326585695, 0.7280632411067194, 0.7145805690697332, 0.6608178211779066, 0.6647066453370228]\n",
            "[0.786096256684492, 0.7663043478260869, 0.75, 0.695906432748538, 0.7151515151515152]\n",
            "0.7031613206554154\n",
            "0.7426917104821265\n",
            "1\n",
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({2: 483, 1: 246})\n",
            "Counter({2: 139, 1: 58})\n",
            "1\n",
            "Counter({2: 492, 1: 243})\n",
            "Counter({2: 130, 1: 61})\n",
            "2\n",
            "Counter({2: 502, 1: 238})\n",
            "Counter({2: 120, 1: 66})\n",
            "3\n",
            "Counter({2: 503, 1: 244})\n",
            "Counter({2: 119, 1: 60})\n",
            "4\n",
            "Counter({2: 508, 1: 245})\n",
            "Counter({2: 114, 1: 59})\n",
            "0.5769529255466755\n",
            "0.7339732142857142\n",
            "*************************\n",
            "[0.6612625890444608, 0.6735042735042736, 0.683359341750603, 0.69002615968461, 0.6820474719430649]\n",
            "[0.7157360406091371, 0.7225130890052356, 0.7419354838709677, 0.7374301675977654, 0.7283236994219653]\n",
            "0.6780399671854024\n",
            "0.7291876961010142\n",
            "2\n",
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({2: 486, 1: 225})\n",
            "Counter({2: 137, 1: 53})\n",
            "1\n",
            "Counter({2: 490, 1: 226})\n",
            "Counter({2: 133, 1: 52})\n",
            "2\n",
            "Counter({2: 500, 1: 222})\n",
            "Counter({2: 123, 1: 56})\n",
            "3\n",
            "Counter({2: 505, 1: 221})\n",
            "Counter({2: 118, 1: 57})\n",
            "4\n",
            "Counter({2: 511, 1: 218})\n",
            "Counter({2: 112, 1: 60})\n",
            "0.6452812465312466\n",
            "0.7332514880952383\n",
            "*************************\n",
            "[0.6955128205128205, 0.6345478489903424, 0.7000781919052761, 0.6536723796721556, 0.6760828625235406]\n",
            "[0.7578947368421053, 0.7081081081081081, 0.7486033519553073, 0.6971428571428572, 0.7209302325581395]\n",
            "0.671978820720827\n",
            "0.7265358573213034\n",
            "3\n",
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
            "  UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({2: 610, 1: 225})\n",
            "Counter({2: 165, 1: 63})\n",
            "1\n",
            "Counter({2: 616, 1: 225})\n",
            "Counter({2: 159, 1: 63})\n",
            "2\n",
            "Counter({2: 620, 1: 232})\n",
            "Counter({2: 155, 1: 56})\n",
            "3\n",
            "Counter({2: 624, 1: 236})\n",
            "Counter({2: 151, 1: 52})\n",
            "4\n",
            "Counter({2: 630, 1: 234})\n",
            "Counter({2: 145, 1: 54})\n",
            "0.5981746898934398\n",
            "0.7353199404761904\n",
            "*************************\n",
            "[0.6569679969399465, 0.6181630546955624, 0.641156462585034, 0.6771799628942485, 0.5397278911564626]\n",
            "[0.7412280701754386, 0.7297297297297297, 0.7440758293838863, 0.7635467980295566, 0.6582914572864321]\n",
            "0.6266390736542508\n",
            "0.7273743769210086\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_all.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQyM4eQsz4sD",
        "outputId": "0923bb3c-52c2-440c-a63b-e5605f1ea22b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1063, 327)\n"
          ]
        }
      ]
    }
  ]
}