{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PSD_PLV_version2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "83ad278a589344d78c405a29ad7fcddb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9e5b97066e774055ad572709eefbdeb1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d42d61c0e4df4b90b9adef0bb609c738",
              "IPY_MODEL_2745efd5d1784921ad369e2fee966ec1",
              "IPY_MODEL_8eb54c98463b493bb97f902dead50ac5"
            ]
          }
        },
        "9e5b97066e774055ad572709eefbdeb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d42d61c0e4df4b90b9adef0bb609c738": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_32f89caa93d74be1a1f45d8014bccb0c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "training...:  25%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_09d50ba3371d4f2da8c67aeb06ca93d8"
          }
        },
        "2745efd5d1784921ad369e2fee966ec1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_24086cb373cc48a6a372da79f726b006",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 40,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 11,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d5da2260edbe42a48106c5fc1be6b8ee"
          }
        },
        "8eb54c98463b493bb97f902dead50ac5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a0f6779823004becbe60a91fcee1ce70",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10/40 [00:05&lt;00:15,  2.00it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_23ffa4ae089b4f69a45a2c60394e0931"
          }
        },
        "32f89caa93d74be1a1f45d8014bccb0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "09d50ba3371d4f2da8c67aeb06ca93d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "24086cb373cc48a6a372da79f726b006": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d5da2260edbe42a48106c5fc1be6b8ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a0f6779823004becbe60a91fcee1ce70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "23ffa4ae089b4f69a45a2c60394e0931": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8JYcp_4XLV7"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchtext\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
        "import numpy as np\n",
        "from  scipy import stats\n",
        "import scipy\n",
        "np.random.seed(1)\n",
        "torch.manual_seed(1)\n",
        "random.seed(1)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlNsBL96YiCD"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/MADE/Project/deap\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEw0N3rmYkQ_"
      },
      "source": [
        "class Args:\n",
        "  def __init__(self): #(data_path, epoch, batch_siz, image_size, learning_rate, weight_deca, learning_rate, learning_rate_gamma, weight_bce, load, output_dir)\n",
        "    self.data_path = \"/content/drive/MyDrive/MADE/semester2/CV/contest02/data/\"\n",
        "    self.epochs = 2\n",
        "    self.batch_size = 256\n",
        "    self.lr= 3e-4\n",
        "    self.weight_decay= 1e-6\n",
        "    self.learning_rate=None\n",
        "    self.learning_rate_gamma=None\n",
        "    self.weight_bce=1\n",
        "    self.load=None\n",
        "    self.output_dir=\"/content/drive/MyDrive/MADE/Project/RACNN_models/\"\n",
        "    self.data_dir =\"./data_preprocessed_python/\"# \"/content/drive/MyDrive/MADE/Project/train/physionet.org/\"\n",
        "args = Args()   "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uul6VvjtYoFb"
      },
      "source": [
        "import glob\n",
        "import pickle\n",
        "from collections import Counter\n",
        "import scipy\n",
        "from  scipy import signal\n",
        "from scipy.fft import fft, fftfreq"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1MO2eTqY0fb"
      },
      "source": [
        "import glob\n",
        "import pickle\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "data = []\n",
        "labels = []\n",
        "data_dir = './data_preprocessed_python'\n",
        "files = glob.glob(os.path.join(data_dir, \"*.dat\"))\n",
        "data_raw = []\n",
        "for file_data in files:\n",
        "    raw_data = pickle.load(open(file_data, 'rb'), encoding='latin1')\n",
        "    data.append(raw_data['data'])\n",
        "    labels.append(raw_data['labels'])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pmm_HCogZB-I"
      },
      "source": [
        "labels_bin = []\n",
        "for sub in range(32):\n",
        "  temp = labels[sub] >= 4.5\n",
        "  labels_bin.append(temp)\n",
        "  #print(sum(labels_bin[sub][:, type_emotion]), end=' ')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZhJBeZQZiI1"
      },
      "source": [
        "LEN_RECORD_IN_SECONDS = 60\n",
        "NVIDEOS = 40\n",
        "HCANALS = 9\n",
        "WCANALS = 9\n",
        "NTIMES_IN_SAMPLE = 128\n",
        "NTIMES_IN_SEC = 128\n",
        "NCANALS = 32\n",
        "NFEATURES = 32\n",
        "NSUBJECTS = 32\n",
        "electrode_matrix = {}\n",
        "electrode_matrix['FP1'] = [0, 3]\n",
        "electrode_matrix['FP2'] = [0, 5]\n",
        "electrode_matrix['AF3'] = [1, 3]\n",
        "electrode_matrix['AF4'] = [1, 5]\n",
        "electrode_matrix['F7']  = [2, 0]\n",
        "electrode_matrix['F3']  = [2, 2]\n",
        "electrode_matrix['FZ']  = [2, 4]\n",
        "electrode_matrix['F4']  = [2, 6]\n",
        "electrode_matrix['F8']  = [2, 8]\n",
        "electrode_matrix['FC5']  = [3, 1]\n",
        "electrode_matrix['FC1']  = [3, 3]\n",
        "electrode_matrix['FC2']  = [3, 5]\n",
        "electrode_matrix['FC6']  = [3, 7]\n",
        "electrode_matrix['T7']  = [4, 0]\n",
        "electrode_matrix['C3']  = [4, 2]\n",
        "electrode_matrix['CZ']  = [4, 4]\n",
        "electrode_matrix['C4']  = [4, 6]\n",
        "electrode_matrix['T8']  = [4, 8]\n",
        "electrode_matrix['CP5']  = [5, 1]\n",
        "electrode_matrix['CP1']  = [5, 3]\n",
        "electrode_matrix['CP2']  = [5, 5]\n",
        "electrode_matrix['CP6']  = [5, 7]\n",
        "electrode_matrix['P7']  = [6, 0]\n",
        "electrode_matrix['P3']  = [6, 2]\n",
        "electrode_matrix['PZ']  = [6, 4]\n",
        "electrode_matrix['P4']  = [6, 6]\n",
        "electrode_matrix['P8']  = [6, 8]\n",
        "electrode_matrix['PO3'] = [7, 3]\n",
        "electrode_matrix['PO4'] = [7, 5]\n",
        "electrode_matrix['O1'] = [8, 3]\n",
        "electrode_matrix['OZ'] = [8, 4]\n",
        "electrode_matrix['O2'] = [8, 5]\n",
        "\n",
        "list_electrodes = ['FP1', 'AF3', 'F3', 'F7', 'FC5', 'FC1', 'C3',\t'T7',\t'CP5',\t'CP1',\t'P3',\t'P7',\t'PO3',\t'O1',\t'OZ',\t'PZ',\t'FP2',\t'AF4', 'FZ', 'F4', 'F8', 'FC6',\t'FC2',\t'CZ', 'C4', 'T8', 'CP6',\t'CP2',\t'P4', \t'P8',\t'PO4',\t'O2']\n",
        "data_dir = './data_preprocessed_python'\n",
        "TRAIN_SIZE = 0.9\n",
        "THRESHOLD = 4.5"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqaxTpN0YpTe"
      },
      "source": [
        "class EmotionDataset(Dataset):\n",
        "    def __init__ (self, data, labels_bin, transforms, interval, shift, seq, type):  #indexes - индексы видео которые вошли в датасет, data - данные labels - метки бинарные\n",
        "       self.data_samples = []\n",
        "       self.labels = []\n",
        "       self.transforms = transforms\n",
        "       self.cnt = [Counter(), Counter(), Counter(),Counter()]\n",
        "       for sub in range(len(data)): #sub   - человек\n",
        "          for nvideo in range(NVIDEOS):\n",
        "             for nsec in range(0, LEN_RECORD_IN_SECONDS - interval, shift):\n",
        "                    data_sample = data[sub][nvideo, :,  (3 + nsec) * NTIMES_IN_SEC : (3 + nsec + interval) * NTIMES_IN_SEC]\n",
        "                    psd_sample = fft(data_sample)\n",
        "                    self.data_samples.append(psd_sample)\n",
        "                    self.labels.append(labels_bin[sub][nvideo, :])\n",
        "       n = len(self.data_samples)\n",
        "       #seq = np.arange(n)\n",
        "       #random.shuffle(seq)\n",
        "       size = int(koeff * n)\n",
        "       print(n)\n",
        "       if type == 'train':\n",
        "            self.data_samples = np.array(self.data_samples)[np.array(seq)][0 : size]\n",
        "            self.labels = np.array(self.labels)[np.array(seq)][0 : size]\n",
        "       else:\n",
        "             self.data_samples = np.array(self.data_samples)[seq][size : ]\n",
        "             self.labels = np.array(self.labels)[seq][size : ]\n",
        "\n",
        "    def __len__(self):\n",
        "       result =  len(self.data_samples)\n",
        "       return result\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "       sample = {}   \n",
        "       sample = {\"labels\": self.labels[item],\n",
        "                 \"data\": self.data_samples[item]\n",
        "       }\n",
        "\n",
        "       if self.transforms is not None:\n",
        "           for t in self.transforms:\n",
        "                sample = t(sample)\n",
        "       #print(sample)         \n",
        "       return sample\n",
        "                 \n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-Bgkq8a8rwH"
      },
      "source": [
        "delta (0-3 Hz), theta (4-7\n",
        "Hz), low alpha (8-9.5 Hz), high alpha (10.5-12 Hz), alpha (8-\n",
        "12 Hz), low beta (13-16 Hz), mid beta (17-20 Hz), high beta\n",
        "(21-29 Hz), beta (13-29 Hz), and gamma (30-50 Hz)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vWngb8RcqON"
      },
      "source": [
        "# class Compose(object):\n",
        "#     def __init__(self, transforms):\n",
        "#         super(Compose, self).__init__()\n",
        "#         self.transforms = transforms\n",
        "\n",
        "#     def __call__(self, sample):\n",
        "#         for t in self.transforms:\n",
        "#             sample = t(sample)\n",
        "#         return sample\n",
        "\n",
        " \n",
        "class to_pcc_matrix_per_freq(object):\n",
        "    def __init__(self):\n",
        "        super(to_pcc_matrix_per_freq, self).__init__()\n",
        "  \n",
        "    def __call__(self, sample: dict):\n",
        "         freq_data = sample['data'].copy()\n",
        "         freq_ranges_gc = np.array([0, 3, 4, 7, 8, 9.5, 10.5, 12, 8, 12, 13, 16, 17,20, 21, 29, 13, 29, 30, 50])\n",
        "         koeff = 0.5\n",
        "         freq_ranges_ind = ((freq_ranges_gc)/0.5).astype(int)\n",
        "         list_canals = np.arange(NCANALS)\n",
        "         #random.shuffle(list_canals)\n",
        "         freq_data_new = np.array(freq_data).real\n",
        "         pcc_matrixes = []\n",
        "         for s in range(10):\n",
        "            ind_begin = freq_ranges_ind[s * 2]\n",
        "            ind_end = freq_ranges_ind[s * 2 + 1]\n",
        "            #print(ind_begin)\n",
        "            ##print(ind_end)\n",
        "            #print(freq_data_new.shape)\n",
        "            #print(\"*****\")\n",
        "            pcc_matrix = np.zeros((9, 9))\n",
        "            for i in range(NCANALS):\n",
        "                #print(electrode_matrix[list_electrodes[i]][0])\n",
        "                #print(freq_data_new)\n",
        "                pcc_matrix[electrode_matrix[list_electrodes[i]][0], electrode_matrix[list_electrodes[i]][1]]  = (freq_data_new[i, ind_begin : ind_end] ** 2).sum()\n",
        "            #np.corrcoef(freq_data_new[:, ind_begin : ind_end])\n",
        "            # for i in range(NCANALS):\n",
        "            #    for j in range(i + 1):\n",
        "            #       pcc_matrix[i, j] = pcc_matrix[i, j]/(np.std(freq_data_new[i, ind_begin : ind_end]) * np.std(freq_data_new[j, ind_begin : ind_end]))\n",
        "            #       pcc_matrix[j, i] = pcc_matrix[i, j]\n",
        "            pcc_matrixes.append(pcc_matrix)\n",
        "         sample['data'] = pcc_matrixes\n",
        "         #print(pcc_matrix)\n",
        "         return(sample)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# class to_pcc_matrix(object):\n",
        "#     def __init__(self):\n",
        "#         super(to_pcc_matrix, self).__init__()\n",
        "        \n",
        "\n",
        "#     def __call__(self, sample: dict):\n",
        "#         canal_data = sample['data'].copy()\n",
        "#         list_canals = np.arange(NCANALS)\n",
        "#         random.shuffle(list_canals)\n",
        "#         canal_data_new = [canal_data[list_canals[i]] for i in range(32)]\n",
        "#         pcc_matrix = np.cov(canal_data_new)\n",
        "#         for i in range(NCANALS):\n",
        "#            for j in range(i + 1):\n",
        "#               pcc_matrix[i, j] = pcc_matrix[i, j]/(np.std(canal_data_new[i]) * np.std(canal_data_new[j]))\n",
        "#               pcc_matrix[j, i] = pcc_matrix[i, j]\n",
        "#         sample['data'] = pcc_matrix\n",
        "#         #print(pcc_matrix)\n",
        "#         return(sample)\n",
        "\n",
        "class ToTensor(object):\n",
        "\n",
        "    def __init__(self, ):\n",
        "        super(ToTensor, self).__init__()\n",
        "\n",
        "    def __call__(self, sample: dict):\n",
        "        return {\"labels\": torch.tensor(sample[\"labels\"], dtype=torch.long),\n",
        "                \"data\": torch.tensor(sample[\"data\"], dtype=torch.float32),\n",
        "                } \n",
        "\n",
        "\n",
        "transforms = [to_pcc_matrix_per_freq(),\n",
        "                   ToTensor()]                       "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qvGtNlztH8X"
      },
      "source": [
        "def get_conv_module(n_input_channels,n_output_channels):\n",
        "  conv = nn.Conv2d(n_input_channels, n_output_channels, kernel_size = 3, stride=1, padding='same')\n",
        "  maxpool = nn.MaxPool2d(kernel_size = 2)\n",
        "  bn = nn.BatchNorm2d(n_output_channels)\n",
        "  relu = nn.ReLU()\n",
        "  result = torch.nn.Sequential(conv, maxpool, bn, relu)\n",
        "  return(result)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_2KngC8ruqp"
      },
      "source": [
        "class EmotionNet(torch.nn.Module): \n",
        "   def __init__(self, hcanals, wcanals, tures, ntimes_in_sample):\n",
        "      super().__init__()\n",
        "      #print(\"1\")\n",
        "      n_input_channels = [10, 32, 64]\n",
        "      n_output_channels = [32, 64, 128]\n",
        "      self.convs = nn.ModuleList([get_conv_module(n_input_channels[i], n_output_channels[i]) for i in range(2)])\n",
        "      self.conv = nn.Conv2d(n_input_channels[2], n_output_channels[2], kernel_size = 3, stride=1, padding='same')\n",
        "      self.flat = nn.Flatten(1, 3)\n",
        "      self.fc = nn.Linear(512, 2)\n",
        "\n",
        "      \n",
        "   def forward(self, input):\n",
        "      #print(f\"input_shape = {input.shape}\")\n",
        "      #input = input.unsqueeze(3)\n",
        "      #input = input.permute(0, 3, 1, 2)\n",
        "      #input (bs, h=32, w=32, 1)\n",
        "\n",
        "      output = input\n",
        "      for i, conv in enumerate(self.convs):\n",
        "            output = conv(output)\n",
        "            #print(outputs[i])\n",
        "      output = self.conv(output)\n",
        "      output = self.flat(output)\n",
        "      #output (bs, s * 256,  h=9, w=9)\n",
        "      output = self.fc(output)\n",
        "      return output\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OU_R_oC7G7zr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52223301-7649-4dd2-e080-0c04e0c44cca"
      },
      "source": [
        "interval = 3\n",
        "shift = 6\n",
        "koeff = 0.8\n",
        "#inds = np.arange(72960)\n",
        "inds = np.arange(12800)\n",
        "random.shuffle(inds)\n",
        "train_dataset = EmotionDataset(data, labels_bin, transforms, interval, shift, inds, 'train')\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=args.batch_size, num_workers=1,\n",
        "                               pin_memory=True, shuffle=True, drop_last=True)\n",
        "\n",
        "\n",
        "val_dataset = EmotionDataset(data, labels_bin, transforms, interval, shift, inds, 'test')\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=args.batch_size, num_workers=1,\n",
        "                               pin_memory=True, shuffle=False, drop_last=False)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12800\n",
            "12800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJuwzo7gaEGc",
        "outputId": "5d7a14cd-3654-4e63-994a-d8765815162a"
      },
      "source": [
        "sample = val_dataset.__getitem__(300)\n",
        "print(sample['data'].shape)\n",
        "print(sample['data'][0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 9, 9])\n",
            "tensor([[    0.0000,     0.0000,     0.0000,    32.8349,     0.0000,  6285.0234,\n",
            "             0.0000,     0.0000,     0.0000],\n",
            "        [    0.0000,     0.0000,     0.0000,  4208.7188,     0.0000, 11422.3262,\n",
            "             0.0000,     0.0000,     0.0000],\n",
            "        [ 7745.1992,     0.0000,   668.3880,     0.0000,  7886.3481,     0.0000,\n",
            "           931.1592,     0.0000, 10750.8965],\n",
            "        [    0.0000,   799.8622,     0.0000,  1979.7362,     0.0000, 21304.4648,\n",
            "             0.0000,  2789.2180,     0.0000],\n",
            "        [ 1797.8057,     0.0000,  5571.3882,     0.0000,  6891.3789,     0.0000,\n",
            "          3348.4307,     0.0000,  4846.2485],\n",
            "        [    0.0000,  1910.5140,     0.0000,  4067.2664,     0.0000,  5997.4199,\n",
            "             0.0000,   642.5306,     0.0000],\n",
            "        [   46.8583,     0.0000,  1200.8201,     0.0000,  1378.9672,     0.0000,\n",
            "         14099.8848,     0.0000,  1139.0491],\n",
            "        [    0.0000,     0.0000,     0.0000, 11428.2334,     0.0000,  3144.6272,\n",
            "             0.0000,     0.0000,     0.0000],\n",
            "        [    0.0000,     0.0000,     0.0000,  6060.6157, 11858.6006,  4296.3916,\n",
            "             0.0000,     0.0000,     0.0000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y86cOSsmHM9Q"
      },
      "source": [
        "def train(model, loader, criterion, optimizer, device, batch = None):\n",
        "    model.train()\n",
        "    train_loss = []\n",
        "    inputs = []\n",
        "   \n",
        "    #lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)#, mode='min', factor=0.1, patience=10, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08, verbose=False)\n",
        "    for batch in tqdm(loader, total=len(loader), desc=\"training...\", position=0 , leave = True):\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            src  = batch['data'].to(device)\n",
        "            #print(src.shape)\n",
        "            trg = batch['labels'][:, 0]\n",
        "\n",
        "            #print(batch)\n",
        "            #print(trg.shape)\n",
        "            levels_pred = model(src)  # B x (2 * NUM_PTS)\n",
        "            #print(levels_pred.shape)\n",
        "            levels_pred = levels_pred.cpu()\n",
        "\n",
        "            #usual cross entropy\n",
        "            #output = levels_pred[:, 1:].reshape(-1, levels_pred.shape[-1])\n",
        "            #trg1 = trg[:, 1:].reshape(-1)\n",
        "            loss = criterion(levels_pred, trg) \n",
        "\n",
        "            #print(\"after\")\n",
        "            train_loss.append(loss.item())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            #break\n",
        "    return np.mean(train_loss)#, mid_outputs"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltPJdcApHQ9Q"
      },
      "source": [
        "def evaluate(model, loader, criterion, device):\n",
        "    \n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    history = []\n",
        "  \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for s, batch in enumerate(tqdm(loader, total=len(loader), desc=\"validating...\", position=0 , leave = True)):\n",
        "            src  = batch['data'].to(device)\n",
        "            #print(src.shape)\n",
        "            trg = batch['labels'][:, 0]\n",
        "\n",
        "\n",
        "\n",
        "            levels_pred = model(src)  # B x (2 * NUM_PTS)\n",
        "            #print(levels_pred.shape)\n",
        "            levels_pred = levels_pred.cpu()\n",
        "\n",
        "            \n",
        "            loss = criterion(levels_pred, trg) \n",
        "\n",
        "            epoch_loss += loss.item() \n",
        "        \n",
        "    return epoch_loss / s\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix,classification_report"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1K3lPyI-HUpR"
      },
      "source": [
        "def calculate_predictions(model, loader):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    history = []\n",
        "    real = []\n",
        "    pred = []\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for i, batch in enumerate(tqdm(loader, total=len(loader), desc=\"predicting...\", position=0 , leave = True)):\n",
        "            src  = batch['data'].to(device)\n",
        "            #print(src.shape)\n",
        "            trg = batch['labels'][:, 0]\n",
        "           \n",
        "\n",
        "            levels_pred = model(src)  # B x (2 * NUM_PTS)\n",
        "            levels_pred = levels_pred.cpu()\n",
        "            #print(levels_pred.shape)\n",
        "            trg_pred = levels_pred.argmax(1)\n",
        "            \n",
        "            real.extend(trg)\n",
        "            pred.extend(trg_pred) \n",
        "\n",
        "            \n",
        "        print(accuracy_score(real, pred)) \n",
        "        print(confusion_matrix(real, pred))  \n",
        "        print(classification_report(real, pred))   \n",
        "        #plt.hist(real)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cy-tCTeIfzIt",
        "outputId": "ceb1fa17-c961-4046-b5d9-8eb28acd8d7e"
      },
      "source": [
        "def get_model():\n",
        "  model = EmotionNet(HCANALS, WCANALS, NFEATURES, NTIMES_IN_SAMPLE).to(device)\n",
        "  return model\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = get_model()\n",
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)\n",
        "\n",
        "model.apply(initialize_weights)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EmotionNet(\n",
              "  (convs): ModuleList(\n",
              "    (0): Sequential(\n",
              "      (0): Conv2d(10, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (3): ReLU()\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "      (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (3): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (flat): Flatten(start_dim=1, end_dim=3)\n",
              "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSrCAGHUf2Er"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss(reduction = 'mean')#torch.nn.MSELoss()\n",
        "#optimizer = optim.SGD(model.parameters(), lr=3e-5, momentum = 0.9)#, weight_decay=args.weight_decay)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-5)#, momentum = 0.9)#, weight_decay=args.weight_decay)\n",
        "# print(train_dataset.cnt)\n",
        "# print(val_dataset.cnt)\n",
        "# print(files[ind_train])\n",
        "# print(files[ind_val])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOT0qjQSLPUy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48,
          "referenced_widgets": [
            "83ad278a589344d78c405a29ad7fcddb",
            "9e5b97066e774055ad572709eefbdeb1",
            "d42d61c0e4df4b90b9adef0bb609c738",
            "2745efd5d1784921ad369e2fee966ec1",
            "8eb54c98463b493bb97f902dead50ac5",
            "32f89caa93d74be1a1f45d8014bccb0c",
            "09d50ba3371d4f2da8c67aeb06ca93d8",
            "24086cb373cc48a6a372da79f726b006",
            "d5da2260edbe42a48106c5fc1be6b8ee",
            "a0f6779823004becbe60a91fcee1ce70",
            "23ffa4ae089b4f69a45a2c60394e0931"
          ]
        },
        "outputId": "349d596f-a60e-42d2-a5eb-8ae3512939d5"
      },
      "source": [
        "args.epochs = 20000\n",
        "#criterion =  fnn.mse_loss\n",
        "train_loss_min = 10000\n",
        "val_loss_min = 10000\n",
        "#batch = next(iter(train_dataloader))\n",
        "for epoch in range(args.epochs):\n",
        "    #logger.info(f\"Starting epoch {epoch + 1}/{args.epochs}.\")\n",
        "    \n",
        "    train_loss = train(model, train_dataloader, criterion, optimizer ,device)\n",
        "    #if epoch % 500 == 0:\n",
        "    print(train_loss)\n",
        "\n",
        "    if (train_loss < train_loss_min):\n",
        "        train_loss_min      = train_loss\n",
        "        torch.save({\n",
        "                         'model_state_dict': model.state_dict(),\n",
        "                         'optimizer_state_dict': optimizer.state_dict(),\n",
        "                       },\n",
        "                       os.path.join(\"/content/drive/MyDrive/MADE/Project/CNN_models/\", \"train.tgz\")\n",
        "            )  \n",
        "\n",
        "    val_loss = evaluate(model, val_dataloader, criterion, device)\n",
        "    # #break\n",
        "    print(val_loss)\n",
        "    #break\n",
        "\n",
        "    # #calculate_predictions(model, val_dataloader)\n",
        "    if (val_loss < val_loss_min):\n",
        "         val_loss_min      = val_loss\n",
        "         torch.save({'model_state_dict': model.state_dict(),    'optimizer_state_dict': optimizer.state_dict(),}, os.path.join(\"/content/drive/MyDrive/MADE/Project/CNN_models/\", f\"val.tgz\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "83ad278a589344d78c405a29ad7fcddb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "training...:   0%|          | 0/40 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33X5NKTqkRGt"
      },
      "source": [
        "val_loss = evaluate(model, val_dataloader, criterion, device)\n",
        "# #break\n",
        "print(val_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DO8LGRb6tN4b"
      },
      "source": [
        "calculate_predictions(model, val_dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}